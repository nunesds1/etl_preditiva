2025-12-02 23:57:34,627 INFO org.apache.hadoop.hdfs.server.namenode.NameNode - STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = namenode/172.18.0.3
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.3.6
STARTUP_MSG:   classpath = /opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/curator-framework-5.2.0.jar:/opt/hadoop/share/hadoop/common/lib/jersey-core-1.19.4.jar:/opt/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/opt/hadoop/share/hadoop/common/lib/commons-net-3.9.0.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/opt/hadoop/share/hadoop/common/lib/jetty-server-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-http2-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-classes-epoll-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/opt/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-handler-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/opt/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-udt-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jersey-json-1.20.jar:/opt/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-native-unix-common-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/netty-common-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-stomp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.4.jar:/opt/hadoop/share/hadoop/common/lib/commons-configuration2-2.8.0.jar:/opt/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/hadoop/common/lib/netty-handler-proxy-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.6.jar:/opt/hadoop/share/hadoop/common/lib/jetty-security-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jetty-io-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-native-epoll-4.1.89.Final-linux-aarch_64.jar:/opt/hadoop/share/hadoop/common/lib/commons-text-1.10.0.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-xml-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-all-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-resolver-dns-classes-macos-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jetty-http-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-mqtt-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-resolver-dns-native-macos-4.1.89.Final-osx-aarch_64.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.6.jar:/opt/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/zookeeper-3.6.3.jar:/opt/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop/share/hadoop/common/lib/gson-2.9.0.jar:/opt/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/opt/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-native-epoll-4.1.89.Final-linux-x86_64.jar:/opt/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/opt/hadoop/share/hadoop/common/lib/netty-resolver-dns-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-resolver-dns-native-macos-4.1.89.Final-osx-x86_64.jar:/opt/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-handler-ssl-ocsp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-dns-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/curator-recipes-5.2.0.jar:/opt/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/opt/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-native-kqueue-4.1.89.Final-osx-aarch_64.jar:/opt/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/hadoop/common/lib/jetty-util-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/opt/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/opt/hadoop/share/hadoop/common/lib/jetty-xml-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/jersey-server-1.19.4.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-redis-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-memcache-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-classes-kqueue-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/zookeeper-jute-3.6.3.jar:/opt/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-rxtx-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-smtp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-socks-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-http-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-native-kqueue-4.1.89.Final-osx-x86_64.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-haproxy-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/opt/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/hadoop/common/lib/netty-resolver-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/curator-client-5.2.0.jar:/opt/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/opt/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/opt/hadoop/share/hadoop/common/lib/netty-buffer-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/hadoop/common/lib/jettison-1.5.4.jar:/opt/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-sctp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/hadoop/common/hadoop-common-3.3.6-tests.jar:/opt/hadoop/share/hadoop/common/hadoop-kms-3.3.6.jar:/opt/hadoop/share/hadoop/common/hadoop-nfs-3.3.6.jar:/opt/hadoop/share/hadoop/common/hadoop-registry-3.3.6.jar:/opt/hadoop/share/hadoop/common/hadoop-common-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/curator-framework-5.2.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-net-3.9.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-json-1.20.jar:/opt/hadoop/share/hadoop/hdfs/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/opt/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.8.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/HikariCP-java7-2.4.12.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.89.Final-linux-aarch_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-text-1.10.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.89.Final-osx-aarch_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/zookeeper-3.6.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop/share/hadoop/hdfs/lib/gson-2.9.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/opt/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.89.Final-linux-x86_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.89.Final-osx-x86_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-handler-ssl-ocsp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/curator-recipes-5.2.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.89.Final-osx-aarch_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.6.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.89.Final-osx-x86_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/opt/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/curator-client-5.2.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jettison-1.5.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.6-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.6-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.6-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.6-tests.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.6-tests.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.6.jar:/opt/hadoop/share/hadoop/yarn:/opt/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/opt/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/asm-tree-9.4.jar:/opt/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.68.jar:/opt/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/asm-commons-9.4.jar:/opt/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/opt/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/opt/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/opt/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/opt/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop/share/hadoop/yarn/lib/snakeyaml-2.0.jar:/opt/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.4.jar:/opt/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/opt/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.68.jar:/opt/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/opt/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.4.jar:/opt/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/opt/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.6.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r 1be78238728da9266a4f88195058f08fd012bf9c; compiled by 'ubuntu' on 2023-06-18T08:22Z
STARTUP_MSG:   java = 11.0.29
************************************************************/
2025-12-02 23:57:34,638 INFO org.apache.hadoop.hdfs.server.namenode.NameNode - registered UNIX signal handlers for [TERM, HUP, INT]
2025-12-02 23:57:34,734 INFO org.apache.hadoop.hdfs.server.namenode.NameNode - createNameNode []
2025-12-02 23:57:34,839 WARN org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-namenode.properties,hadoop-metrics2.properties
2025-12-02 23:57:34,957 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2025-12-02 23:57:34,958 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl - NameNode metrics system started
2025-12-02 23:57:34,978 INFO org.apache.hadoop.hdfs.server.namenode.NameNodeUtils - fs.defaultFS is hdfs://namenode:9000
2025-12-02 23:57:34,979 INFO org.apache.hadoop.hdfs.server.namenode.NameNode - Clients should use namenode:9000 to access this namenode/service.
2025-12-02 23:57:35,165 INFO org.apache.hadoop.util.JvmPauseMonitor - Starting JVM pause monitor
2025-12-02 23:57:35,197 INFO org.apache.hadoop.hdfs.DFSUtil - Filter initializers set : org.apache.hadoop.http.lib.StaticUserWebFilter,org.apache.hadoop.hdfs.web.AuthFilterInitializer
2025-12-02 23:57:35,205 INFO org.apache.hadoop.hdfs.DFSUtil - Starting Web-server for hdfs at: http://namenode:9870
2025-12-02 23:57:35,220 INFO org.eclipse.jetty.util.log - Logging initialized @1355ms to org.eclipse.jetty.util.log.Slf4jLog
2025-12-02 23:57:35,363 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-12-02 23:57:35,381 INFO org.apache.hadoop.http.HttpRequestLog - Http request log for http.requests.namenode is not defined
2025-12-02 23:57:35,391 INFO org.apache.hadoop.http.HttpServer2 - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2025-12-02 23:57:35,393 INFO org.apache.hadoop.http.HttpServer2 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2025-12-02 23:57:35,393 INFO org.apache.hadoop.http.HttpServer2 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-12-02 23:57:35,393 INFO org.apache.hadoop.http.HttpServer2 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-12-02 23:57:35,396 INFO org.apache.hadoop.http.HttpServer2 - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context hdfs
2025-12-02 23:57:35,397 INFO org.apache.hadoop.http.HttpServer2 - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context logs
2025-12-02 23:57:35,397 INFO org.apache.hadoop.http.HttpServer2 - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context static
2025-12-02 23:57:35,449 INFO org.apache.hadoop.http.HttpServer2 - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2025-12-02 23:57:35,465 INFO org.apache.hadoop.http.HttpServer2 - Jetty bound to port 9870
2025-12-02 23:57:35,466 INFO org.eclipse.jetty.server.Server - jetty-9.4.51.v20230217; built: 2023-02-17T08:19:37.309Z; git: b45c405e4544384de066f814ed42ae3dceacdd49; jvm 11.0.29+7-post-Ubuntu-1ubuntu122.04
2025-12-02 23:57:35,505 INFO org.eclipse.jetty.server.session - DefaultSessionIdManager workerName=node0
2025-12-02 23:57:35,505 INFO org.eclipse.jetty.server.session - No SessionScavenger set, using defaults
2025-12-02 23:57:35,507 INFO org.eclipse.jetty.server.session - node0 Scavenging every 660000ms
2025-12-02 23:57:35,526 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-12-02 23:57:35,529 INFO org.eclipse.jetty.server.handler.ContextHandler - Started o.e.j.s.ServletContextHandler@7096b474{logs,/logs,file:///opt/hadoop/logs/,AVAILABLE}
2025-12-02 23:57:35,530 INFO org.eclipse.jetty.server.handler.ContextHandler - Started o.e.j.s.ServletContextHandler@5d1659ea{static,/static,file:///opt/hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2025-12-02 23:57:35,680 INFO org.eclipse.jetty.server.handler.ContextHandler - Started o.e.j.w.WebAppContext@c9413d8{hdfs,/,file:///opt/hadoop/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{file:/opt/hadoop/share/hadoop/hdfs/webapps/hdfs}
2025-12-02 23:57:35,700 INFO org.eclipse.jetty.server.AbstractConnector - Started ServerConnector@56a4479a{HTTP/1.1, (http/1.1)}{namenode:9870}
2025-12-02 23:57:35,701 INFO org.eclipse.jetty.server.Server - Started @1835ms
real-time non-blocking time  (microseconds, -R) unlimited
core file size              (blocks, -c) 0
data seg size               (kbytes, -d) unlimited
scheduling priority                 (-e) 0
file size                   (blocks, -f) unlimited
pending signals                     (-i) 31101
max locked memory           (kbytes, -l) unlimited
max memory size             (kbytes, -m) unlimited
open files                          (-n) 1048576
pipe size                (512 bytes, -p) 8
POSIX message queues         (bytes, -q) 819200
real-time priority                  (-r) 0
stack size                  (kbytes, -s) 8192
cpu time                   (seconds, -t) unlimited
max user processes                  (-u) unlimited
virtual memory              (kbytes, -v) unlimited
file locks                          (-x) unlimited
2025-12-02 23:57:35,950 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2025-12-02 23:57:35,950 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem - Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2025-12-02 23:57:36,012 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog - Edit logging is async:true
2025-12-02 23:57:36,090 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - KeyProvider: null
2025-12-02 23:57:36,093 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - fsLock is fair: true
2025-12-02 23:57:36,094 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - Detailed lock hold time metrics enabled: false
2025-12-02 23:57:36,119 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - fsOwner                = root (auth:SIMPLE)
2025-12-02 23:57:36,120 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - supergroup             = supergroup
2025-12-02 23:57:36,120 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - isPermissionEnabled    = true
2025-12-02 23:57:36,120 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - isStoragePolicyEnabled = true
2025-12-02 23:57:36,120 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - HA Enabled: false
2025-12-02 23:57:36,173 INFO org.apache.hadoop.hdfs.server.common.Util - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2025-12-02 23:57:36,447 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager - dfs.block.invalidate.limit : configured=1000, counted=60, effected=1000
2025-12-02 23:57:36,447 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager - dfs.namenode.datanode.registration.ip-hostname-check=true
2025-12-02 23:57:36,454 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2025-12-02 23:57:36,454 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager - The block deletion will start around 2025 Dec 02 23:57:36
2025-12-02 23:57:36,458 INFO org.apache.hadoop.util.GSet - Computing capacity for map BlocksMap
2025-12-02 23:57:36,458 INFO org.apache.hadoop.util.GSet - VM type       = 64-bit
2025-12-02 23:57:36,460 INFO org.apache.hadoop.util.GSet - 2.0% max memory 1.9 GB = 39.0 MB
2025-12-02 23:57:36,460 INFO org.apache.hadoop.util.GSet - capacity      = 2^22 = 4194304 entries
2025-12-02 23:57:36,492 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager - Storage policy satisfier is disabled
2025-12-02 23:57:36,493 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager - dfs.block.access.token.enable = false
2025-12-02 23:57:36,505 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode - dfs.namenode.safemode.threshold-pct = 0.999
2025-12-02 23:57:36,506 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode - dfs.namenode.safemode.min.datanodes = 0
2025-12-02 23:57:36,506 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode - dfs.namenode.safemode.extension = 30000
2025-12-02 23:57:36,507 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager - defaultReplication         = 1
2025-12-02 23:57:36,507 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager - maxReplication             = 512
2025-12-02 23:57:36,507 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager - minReplication             = 1
2025-12-02 23:57:36,507 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager - maxReplicationStreams      = 2
2025-12-02 23:57:36,507 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager - redundancyRecheckInterval  = 3000ms
2025-12-02 23:57:36,507 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager - encryptDataTransfer        = false
2025-12-02 23:57:36,507 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager - maxNumBlocksToLog          = 1000
2025-12-02 23:57:36,581 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory - GLOBAL serial map: bits=29 maxEntries=536870911
2025-12-02 23:57:36,582 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory - USER serial map: bits=24 maxEntries=16777215
2025-12-02 23:57:36,582 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory - GROUP serial map: bits=24 maxEntries=16777215
2025-12-02 23:57:36,582 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory - XATTR serial map: bits=24 maxEntries=16777215
2025-12-02 23:57:36,607 INFO org.apache.hadoop.util.GSet - Computing capacity for map INodeMap
2025-12-02 23:57:36,607 INFO org.apache.hadoop.util.GSet - VM type       = 64-bit
2025-12-02 23:57:36,608 INFO org.apache.hadoop.util.GSet - 1.0% max memory 1.9 GB = 19.5 MB
2025-12-02 23:57:36,608 INFO org.apache.hadoop.util.GSet - capacity      = 2^21 = 2097152 entries
2025-12-02 23:57:36,619 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory - ACLs enabled? true
2025-12-02 23:57:36,620 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory - POSIX ACL inheritance enabled? true
2025-12-02 23:57:36,620 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory - XAttrs enabled? true
2025-12-02 23:57:36,620 INFO org.apache.hadoop.hdfs.server.namenode.NameNode - Caching file names occurring more than 10 times
2025-12-02 23:57:36,629 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2025-12-02 23:57:36,632 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager - SkipList is disabled
2025-12-02 23:57:36,641 INFO org.apache.hadoop.util.GSet - Computing capacity for map cachedBlocks
2025-12-02 23:57:36,641 INFO org.apache.hadoop.util.GSet - VM type       = 64-bit
2025-12-02 23:57:36,643 INFO org.apache.hadoop.util.GSet - 0.25% max memory 1.9 GB = 4.9 MB
2025-12-02 23:57:36,643 INFO org.apache.hadoop.util.GSet - capacity      = 2^19 = 524288 entries
2025-12-02 23:57:36,661 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2025-12-02 23:57:36,661 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics - NNTop conf: dfs.namenode.top.num.users = 10
2025-12-02 23:57:36,661 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2025-12-02 23:57:36,670 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - Retry cache on namenode is enabled
2025-12-02 23:57:36,671 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2025-12-02 23:57:36,684 INFO org.apache.hadoop.util.GSet - Computing capacity for map NameNodeRetryCache
2025-12-02 23:57:36,684 INFO org.apache.hadoop.util.GSet - VM type       = 64-bit
2025-12-02 23:57:36,685 INFO org.apache.hadoop.util.GSet - 0.029999999329447746% max memory 1.9 GB = 598.4 KB
2025-12-02 23:57:36,685 INFO org.apache.hadoop.util.GSet - capacity      = 2^16 = 65536 entries
2025-12-02 23:57:36,734 INFO org.apache.hadoop.hdfs.server.common.Storage - Lock on /opt/hadoop/data/nn/in_use.lock acquired by nodename 71@namenode
2025-12-02 23:57:36,763 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager - Recovering unfinalized segments in /opt/hadoop/data/nn/current
2025-12-02 23:57:36,817 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager - Finalizing edits file /opt/hadoop/data/nn/current/edits_inprogress_0000000000000001004 -> /opt/hadoop/data/nn/current/edits_0000000000000001004-0000000000000001004
2025-12-02 23:57:36,860 INFO org.apache.hadoop.hdfs.server.namenode.FSImage - Planning to load image: FSImageFile(file=/opt/hadoop/data/nn/current/fsimage_0000000000000001003, cpktTxId=0000000000000001003)
2025-12-02 23:57:37,044 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode - Loading 157 INodes.
2025-12-02 23:57:37,109 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode - Successfully loaded 157 inodes
2025-12-02 23:57:37,140 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode - Completed update blocks map and name cache, total waiting duration 2ms.
2025-12-02 23:57:37,149 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf - Loaded FSImage in 0 seconds.
2025-12-02 23:57:37,150 INFO org.apache.hadoop.hdfs.server.namenode.FSImage - Loaded image for txid 1003 from /opt/hadoop/data/nn/current/fsimage_0000000000000001003
2025-12-02 23:57:37,156 INFO org.apache.hadoop.hdfs.server.namenode.FSImage - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@61f80d55 expecting start txid #1004
2025-12-02 23:57:37,157 INFO org.apache.hadoop.hdfs.server.namenode.FSImage - Start loading edits file /opt/hadoop/data/nn/current/edits_0000000000000001004-0000000000000001004 maxTxnsToRead = 9223372036854775807
2025-12-02 23:57:37,160 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream - Fast-forwarding stream '/opt/hadoop/data/nn/current/edits_0000000000000001004-0000000000000001004' to transaction ID 1004
2025-12-02 23:57:37,213 INFO org.apache.hadoop.hdfs.server.namenode.FSImage - Loaded 1 edits file(s) (the last named /opt/hadoop/data/nn/current/edits_0000000000000001004-0000000000000001004) of total size 1048576.0, total edits 1.0, total load time 20.0 ms
2025-12-02 23:57:37,214 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2025-12-02 23:57:37,216 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog - Starting log segment at 1005
2025-12-02 23:57:37,284 INFO org.apache.hadoop.hdfs.server.namenode.NameCache - initialized with 1 entries 71 lookups
2025-12-02 23:57:37,284 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - Finished loading FSImage in 592 msecs
2025-12-02 23:57:37,563 INFO org.apache.hadoop.hdfs.server.namenode.NameNode - RPC server is binding to namenode:9000
2025-12-02 23:57:37,563 INFO org.apache.hadoop.hdfs.server.namenode.NameNode - Enable NameNode state context:false
2025-12-02 23:57:37,581 INFO org.apache.hadoop.ipc.CallQueueManager - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-12-02 23:57:37,600 INFO org.apache.hadoop.ipc.Server - Listener at namenode:9000
2025-12-02 23:57:37,602 INFO org.apache.hadoop.ipc.Server - Starting Socket Reader #1 for port 9000
2025-12-02 23:57:37,700 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2025-12-02 23:57:37,715 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager - Number of blocks under construction: 0
2025-12-02 23:57:37,724 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeAdminDefaultMonitor - Initialized the Default Decommission and Maintenance monitor
2025-12-02 23:57:37,726 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager - Start MarkedDeleteBlockScrubber thread
2025-12-02 23:57:37,730 INFO org.apache.hadoop.hdfs.StateChange - STATE* Safe mode ON. 
The reported blocks 0 needs additional 72 blocks to reach the threshold 0.9990 of total blocks 73.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2025-12-02 23:57:37,782 INFO org.apache.hadoop.ipc.Server - IPC Server Responder: starting
2025-12-02 23:57:37,783 INFO org.apache.hadoop.ipc.Server - IPC Server listener on 9000: starting
2025-12-02 23:57:37,790 INFO org.apache.hadoop.hdfs.server.namenode.NameNode - NameNode RPC up at: namenode/172.18.0.3:9000
2025-12-02 23:57:37,792 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - Starting services required for active state
2025-12-02 23:57:37,793 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory - Initializing quota with 12 thread(s)
2025-12-02 23:57:37,822 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory - Quota initialization completed in 29 milliseconds
name space=157
storage space=8352915
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2025-12-02 23:57:37,833 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor - Starting CacheReplicationMonitor with interval 30000 milliseconds
2025-12-02 23:57:38,789 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* registerDatanode: from DatanodeRegistration(172.18.0.2:9866, datanodeUuid=d02fd027-40dc-452a-aa59-17a9b2edb3fe, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-8de1d889-312c-47f1-9135-cecbc5761ae6;nsid=1122154000;c=1763416835540) storage d02fd027-40dc-452a-aa59-17a9b2edb3fe
2025-12-02 23:57:38,792 INFO org.apache.hadoop.net.NetworkTopology - Adding a new node: /default-rack/172.18.0.2:9866
2025-12-02 23:57:38,793 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager - Registered DN d02fd027-40dc-452a-aa59-17a9b2edb3fe (172.18.0.2:9866).
2025-12-02 23:57:38,933 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor - Adding new storage ID DS-4f9c54b4-f4d4-4ee3-b0b9-9580107a8e16 for DN 172.18.0.2:9866
2025-12-02 23:57:39,039 INFO BlockStateChange - BLOCK* processReport 0xb8dea9e975d5fc5e with lease ID 0xe4df5f9a3db4d700: Processing first storage report for DS-4f9c54b4-f4d4-4ee3-b0b9-9580107a8e16 from datanode DatanodeRegistration(172.18.0.2:9866, datanodeUuid=d02fd027-40dc-452a-aa59-17a9b2edb3fe, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-8de1d889-312c-47f1-9135-cecbc5761ae6;nsid=1122154000;c=1763416835540)
2025-12-02 23:57:39,054 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager - initializing replication queues
2025-12-02 23:57:39,056 INFO org.apache.hadoop.hdfs.StateChange - STATE* Safe mode extension entered. 
The reported blocks 72 has reached the threshold 0.9990 of total blocks 73. The minimum number of live datanodes is not required. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2025-12-02 23:57:39,058 INFO BlockStateChange - BLOCK* processReport 0xb8dea9e975d5fc5e with lease ID 0xe4df5f9a3db4d700: from storage DS-4f9c54b4-f4d4-4ee3-b0b9-9580107a8e16 node DatanodeRegistration(172.18.0.2:9866, datanodeUuid=d02fd027-40dc-452a-aa59-17a9b2edb3fe, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-8de1d889-312c-47f1-9135-cecbc5761ae6;nsid=1122154000;c=1763416835540), blocks: 73, hasStaleStorage: false, processing time: 19 msecs, invalidatedBlocks: 0
2025-12-02 23:57:39,066 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager - Total number of blocks            = 73
2025-12-02 23:57:39,066 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager - Number of invalid blocks          = 0
2025-12-02 23:57:39,066 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager - Number of under-replicated blocks = 0
2025-12-02 23:57:39,066 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager - Number of  over-replicated blocks = 0
2025-12-02 23:57:39,066 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager - Number of blocks being written    = 0
2025-12-02 23:57:39,066 INFO org.apache.hadoop.hdfs.StateChange - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 10 msec
2025-12-02 23:57:45,419 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.3	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2025-12-02 23:57:45,468 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.3	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2025-12-02 23:57:45,488 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.3	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2025-12-02 23:57:45,490 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.3	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2025-12-02 23:57:45,492 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.3	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2025-12-02 23:57:45,494 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.3	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2025-12-02 23:57:45,499 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.3	cmd=slowDataNodesReport	src=null	dst=null	perm=null	proto=rpc
2025-12-02 23:58:01,794 INFO org.apache.hadoop.hdfs.StateChange - STATE* Safe mode ON, in safe mode extension. 
The reported blocks 73 has reached the threshold 0.9990 of total blocks 73. The minimum number of live datanodes is not required. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2025-12-02 23:58:11,797 INFO org.apache.hadoop.hdfs.StateChange - STATE* Safe mode is OFF
2025-12-02 23:58:11,797 INFO org.apache.hadoop.hdfs.StateChange - STATE* Leaving safe mode after 31 secs
2025-12-02 23:58:11,797 INFO org.apache.hadoop.hdfs.StateChange - STATE* Network topology has 1 racks and 1 datanodes
2025-12-02 23:58:11,798 INFO org.apache.hadoop.hdfs.StateChange - STATE* UnderReplicatedBlocks has 0 blocks
2025-12-02 23:58:48,853 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - Roll Edit Log from 172.18.0.3
2025-12-02 23:58:48,858 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog - Rolling edit logs
2025-12-02 23:58:48,858 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog - Ending log segment 1005, 1005
2025-12-02 23:58:48,863 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog - Number of transactions: 2 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 1004 Number of syncs: 2 SyncTimes(ms): 9 
2025-12-02 23:58:48,866 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog - Number of transactions: 2 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 1004 Number of syncs: 3 SyncTimes(ms): 12 
2025-12-02 23:58:48,875 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager - Finalizing edits file /opt/hadoop/data/nn/current/edits_inprogress_0000000000000001005 -> /opt/hadoop/data/nn/current/edits_0000000000000001005-0000000000000001006
2025-12-02 23:58:48,880 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog - Starting log segment at 1007
2025-12-02 23:58:48,970 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.3	cmd=rollEditLog	src=null	dst=null	perm=null	proto=rpc
2025-12-02 23:58:57,164 INFO org.apache.hadoop.util.JvmPauseMonitor - Detected pause in JVM or host machine (eg GC): pause of approximately 1119ms
No GCs detected
2025-12-02 23:59:01,171 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage - Sending fileName: /opt/hadoop/data/nn/current/fsimage_0000000000000001003, fileSize: 11367. Sent total: 11367 bytes. Size of last segment intended to send: -1 bytes.
2025-12-02 23:59:01,371 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage - Sending fileName: /opt/hadoop/data/nn/current/edits_0000000000000001004-0000000000000001004, fileSize: 1048576. Sent total: 1048576 bytes. Size of last segment intended to send: -1 bytes.
2025-12-02 23:59:01,443 INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage - Sending fileName: /opt/hadoop/data/nn/current/edits_0000000000000001005-0000000000000001006, fileSize: 42. Sent total: 42 bytes. Size of last segment intended to send: -1 bytes.
2025-12-02 23:59:02,424 INFO org.apache.hadoop.hdfs.server.namenode.ImageServlet - Rejecting a fsimage due to small time delta and txnid delta. Time since previous checkpoint is 339 expecting at least 2700 txnid delta since previous checkpoint is 3 expecting at least 1000000
Dec 03, 2025 12:04:50 AM com.sun.jersey.api.core.PackagesResourceConfig init
INFO: Scanning for root resource and provider classes in the packages:
  org.apache.hadoop.hdfs.server.namenode.web.resources
  org.apache.hadoop.hdfs.web.resources
Dec 03, 2025 12:04:51 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Root resource classes found:
  class org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods
Dec 03, 2025 12:04:51 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Provider classes found:
  class org.apache.hadoop.hdfs.web.resources.UserProvider
  class org.apache.hadoop.hdfs.web.resources.ExceptionHandler
Dec 03, 2025 12:04:51 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19.4 05/24/2017 03:20 PM'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by com.sun.xml.bind.v2.runtime.reflect.opt.Injector$1 (file:/opt/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar) to method java.lang.ClassLoader.defineClass(java.lang.String,byte[],int,int)
WARNING: Please consider reporting this to the maintainers of com.sun.xml.bind.v2.runtime.reflect.opt.Injector$1
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
Dec 03, 2025 12:04:51 AM com.sun.jersey.spi.inject.Errors processErrorMessages
WARNING: The following warnings have been detected with resource and/or provider classes:
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.getRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.GetOpParam,org.apache.hadoop.hdfs.web.resources.OffsetParam,org.apache.hadoop.hdfs.web.resources.LengthParam,org.apache.hadoop.hdfs.web.resources.RenewerParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,java.util.List,org.apache.hadoop.hdfs.web.resources.XAttrEncodingParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.FsActionParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.TokenKindParam,org.apache.hadoop.hdfs.web.resources.TokenServiceParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StartAfterParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.putRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PutOpParam,org.apache.hadoop.hdfs.web.resources.DestinationParam,org.apache.hadoop.hdfs.web.resources.OwnerParam,org.apache.hadoop.hdfs.web.resources.GroupParam,org.apache.hadoop.hdfs.web.resources.PermissionParam,org.apache.hadoop.hdfs.web.resources.UnmaskedPermissionParam,org.apache.hadoop.hdfs.web.resources.OverwriteParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ReplicationParam,org.apache.hadoop.hdfs.web.resources.BlockSizeParam,org.apache.hadoop.hdfs.web.resources.ModificationTimeParam,org.apache.hadoop.hdfs.web.resources.AccessTimeParam,org.apache.hadoop.hdfs.web.resources.RenameOptionSetParam,org.apache.hadoop.hdfs.web.resources.CreateParentParam,org.apache.hadoop.hdfs.web.resources.TokenArgumentParam,org.apache.hadoop.hdfs.web.resources.AclPermissionParam,org.apache.hadoop.hdfs.web.resources.XAttrNameParam,org.apache.hadoop.hdfs.web.resources.XAttrValueParam,org.apache.hadoop.hdfs.web.resources.XAttrSetFlagParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.CreateFlagParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StoragePolicyParam,org.apache.hadoop.hdfs.web.resources.ECPolicyParam,org.apache.hadoop.hdfs.web.resources.NameSpaceQuotaParam,org.apache.hadoop.hdfs.web.resources.StorageSpaceQuotaParam,org.apache.hadoop.hdfs.web.resources.StorageTypeParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.postRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PostOpParam,org.apache.hadoop.hdfs.web.resources.ConcatSourcesParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.NewLengthParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.deleteRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.DeleteOpParam,org.apache.hadoop.hdfs.web.resources.RecursiveParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
2025-12-03 00:04:51,833 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/recompra/ano=2023/mes=01	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:04:52,638 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/recompra/ano=2023/mes=01/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:04:52,647 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog - Number of transactions: 2 Total time for transactions(ms): 16 Number of transactions batched in Syncs: 0 Number of syncs: 2 SyncTimes(ms): 17 
2025-12-03 00:04:52,686 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073741971_1147, replicas=172.18.0.2:9866 for /datalake/analytics/recompra/ano=2023/mes=01/dados.parquet
2025-12-03 00:04:52,804 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - BLOCK* blk_1073741971_1147 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /datalake/analytics/recompra/ano=2023/mes=01/dados.parquet
2025-12-03 00:04:53,222 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/recompra/ano=2023/mes=01/dados.parquet is closed by DFSClient_NONMAPREDUCE_-1243372901_70
2025-12-03 00:04:53,237 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/recompra/ano=2023/mes=02	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:04:53,257 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/recompra/ano=2023/mes=02/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:04:53,265 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073741972_1148, replicas=172.18.0.2:9866 for /datalake/analytics/recompra/ano=2023/mes=02/dados.parquet
2025-12-03 00:04:53,278 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/recompra/ano=2023/mes=02/dados.parquet is closed by DFSClient_NONMAPREDUCE_1396089483_80
2025-12-03 00:04:53,285 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/recompra/ano=2023/mes=03	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:04:53,302 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/recompra/ano=2023/mes=03/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:04:53,310 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073741973_1149, replicas=172.18.0.2:9866 for /datalake/analytics/recompra/ano=2023/mes=03/dados.parquet
2025-12-03 00:04:53,324 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/recompra/ano=2023/mes=03/dados.parquet is closed by DFSClient_NONMAPREDUCE_-1794650046_85
2025-12-03 00:04:53,330 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/recompra/ano=2023/mes=04	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:04:53,347 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/recompra/ano=2023/mes=04/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:04:53,354 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073741974_1150, replicas=172.18.0.2:9866 for /datalake/analytics/recompra/ano=2023/mes=04/dados.parquet
2025-12-03 00:04:53,367 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - BLOCK* blk_1073741974_1150 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /datalake/analytics/recompra/ano=2023/mes=04/dados.parquet
2025-12-03 00:04:53,770 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/recompra/ano=2023/mes=04/dados.parquet is closed by DFSClient_NONMAPREDUCE_-2142987391_90
2025-12-03 00:04:53,784 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/recompra/ano=2023/mes=05	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:04:53,802 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/recompra/ano=2023/mes=05/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:04:53,811 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073741975_1151, replicas=172.18.0.2:9866 for /datalake/analytics/recompra/ano=2023/mes=05/dados.parquet
2025-12-03 00:04:53,820 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - BLOCK* blk_1073741975_1151 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /datalake/analytics/recompra/ano=2023/mes=05/dados.parquet
2025-12-03 00:04:54,223 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/recompra/ano=2023/mes=05/dados.parquet is closed by DFSClient_NONMAPREDUCE_-542214656_95
2025-12-03 00:04:54,237 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/recompra/ano=2023/mes=06	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:04:54,253 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/recompra/ano=2023/mes=06/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:04:54,260 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073741976_1152, replicas=172.18.0.2:9866 for /datalake/analytics/recompra/ano=2023/mes=06/dados.parquet
2025-12-03 00:04:54,270 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/recompra/ano=2023/mes=06/dados.parquet is closed by DFSClient_NONMAPREDUCE_-12335006_100
2025-12-03 00:04:54,275 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/recompra/ano=2023/mes=07	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:04:54,292 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/recompra/ano=2023/mes=07/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:04:54,301 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073741977_1153, replicas=172.18.0.2:9866 for /datalake/analytics/recompra/ano=2023/mes=07/dados.parquet
2025-12-03 00:04:54,310 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/recompra/ano=2023/mes=07/dados.parquet is closed by DFSClient_NONMAPREDUCE_1920187555_105
2025-12-03 00:04:54,316 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/recompra/ano=2023/mes=08	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:04:54,332 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/recompra/ano=2023/mes=08/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:04:54,340 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073741978_1154, replicas=172.18.0.2:9866 for /datalake/analytics/recompra/ano=2023/mes=08/dados.parquet
2025-12-03 00:04:54,350 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - BLOCK* blk_1073741978_1154 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /datalake/analytics/recompra/ano=2023/mes=08/dados.parquet
2025-12-03 00:04:54,753 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/recompra/ano=2023/mes=08/dados.parquet is closed by DFSClient_NONMAPREDUCE_-1014851773_110
2025-12-03 00:04:54,763 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/recompra/ano=2023/mes=09	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:04:54,778 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/recompra/ano=2023/mes=09/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:04:54,788 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073741979_1155, replicas=172.18.0.2:9866 for /datalake/analytics/recompra/ano=2023/mes=09/dados.parquet
2025-12-03 00:04:54,800 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/recompra/ano=2023/mes=09/dados.parquet is closed by DFSClient_NONMAPREDUCE_-768423624_115
2025-12-03 00:04:54,807 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/recompra/ano=2023/mes=10	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:04:54,823 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/recompra/ano=2023/mes=10/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:04:54,871 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073741980_1156, replicas=172.18.0.2:9866 for /datalake/analytics/recompra/ano=2023/mes=10/dados.parquet
2025-12-03 00:04:54,889 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/recompra/ano=2023/mes=10/dados.parquet is closed by DFSClient_NONMAPREDUCE_-1948844374_120
2025-12-03 00:04:54,897 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/recompra/ano=2023/mes=11	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:04:54,915 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/recompra/ano=2023/mes=11/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:04:54,928 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073741981_1157, replicas=172.18.0.2:9866 for /datalake/analytics/recompra/ano=2023/mes=11/dados.parquet
2025-12-03 00:04:54,944 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - BLOCK* blk_1073741981_1157 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /datalake/analytics/recompra/ano=2023/mes=11/dados.parquet
2025-12-03 00:04:55,346 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/recompra/ano=2023/mes=11/dados.parquet is closed by DFSClient_NONMAPREDUCE_-2130111027_125
2025-12-03 00:04:55,352 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/recompra/ano=2023/mes=12	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:04:55,369 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/recompra/ano=2023/mes=12/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:04:55,390 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073741982_1158, replicas=172.18.0.2:9866 for /datalake/analytics/recompra/ano=2023/mes=12/dados.parquet
2025-12-03 00:04:55,423 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/recompra/ano=2023/mes=12/dados.parquet is closed by DFSClient_NONMAPREDUCE_454950131_130
2025-12-03 00:04:55,431 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/recompra/ano=2024/mes=01	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:04:55,449 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/recompra/ano=2024/mes=01/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:04:55,460 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073741983_1159, replicas=172.18.0.2:9866 for /datalake/analytics/recompra/ano=2024/mes=01/dados.parquet
2025-12-03 00:04:55,480 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - BLOCK* blk_1073741983_1159 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /datalake/analytics/recompra/ano=2024/mes=01/dados.parquet
2025-12-03 00:04:55,882 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/recompra/ano=2024/mes=01/dados.parquet is closed by DFSClient_NONMAPREDUCE_1260594921_135
2025-12-03 00:04:55,891 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/recompra/ano=2024/mes=02	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:04:55,905 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/recompra/ano=2024/mes=02/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:04:55,923 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073741984_1160, replicas=172.18.0.2:9866 for /datalake/analytics/recompra/ano=2024/mes=02/dados.parquet
2025-12-03 00:04:55,951 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/recompra/ano=2024/mes=02/dados.parquet is closed by DFSClient_NONMAPREDUCE_-2039795298_140
2025-12-03 00:04:55,956 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/recompra/ano=2024/mes=03	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:04:55,972 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/recompra/ano=2024/mes=03/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:04:55,983 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073741985_1161, replicas=172.18.0.2:9866 for /datalake/analytics/recompra/ano=2024/mes=03/dados.parquet
2025-12-03 00:04:55,998 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/recompra/ano=2024/mes=03/dados.parquet is closed by DFSClient_NONMAPREDUCE_846448648_145
2025-12-03 00:04:56,004 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/recompra/ano=2024/mes=04	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:04:56,019 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/recompra/ano=2024/mes=04/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:04:56,034 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073741986_1162, replicas=172.18.0.2:9866 for /datalake/analytics/recompra/ano=2024/mes=04/dados.parquet
2025-12-03 00:04:56,048 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/recompra/ano=2024/mes=04/dados.parquet is closed by DFSClient_NONMAPREDUCE_1835639824_150
2025-12-03 00:04:56,054 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/recompra/ano=2024/mes=05	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:04:56,069 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/recompra/ano=2024/mes=05/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:04:56,077 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073741987_1163, replicas=172.18.0.2:9866 for /datalake/analytics/recompra/ano=2024/mes=05/dados.parquet
2025-12-03 00:04:56,106 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/recompra/ano=2024/mes=05/dados.parquet is closed by DFSClient_NONMAPREDUCE_-1895525258_155
2025-12-03 00:04:56,111 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/recompra/ano=2024/mes=06	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:04:56,126 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/recompra/ano=2024/mes=06/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:04:56,135 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073741988_1164, replicas=172.18.0.2:9866 for /datalake/analytics/recompra/ano=2024/mes=06/dados.parquet
2025-12-03 00:04:56,152 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - BLOCK* blk_1073741988_1164 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /datalake/analytics/recompra/ano=2024/mes=06/dados.parquet
2025-12-03 00:04:56,555 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/recompra/ano=2024/mes=06/dados.parquet is closed by DFSClient_NONMAPREDUCE_-2094868258_160
2025-12-03 00:04:56,565 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/recompra/ano=2024/mes=07	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:04:56,580 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/recompra/ano=2024/mes=07/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:04:56,599 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073741989_1165, replicas=172.18.0.2:9866 for /datalake/analytics/recompra/ano=2024/mes=07/dados.parquet
2025-12-03 00:04:56,619 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - BLOCK* blk_1073741989_1165 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /datalake/analytics/recompra/ano=2024/mes=07/dados.parquet
2025-12-03 00:04:57,022 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/recompra/ano=2024/mes=07/dados.parquet is closed by DFSClient_NONMAPREDUCE_331733205_165
2025-12-03 00:04:57,035 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/recompra/ano=2024/mes=08	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:04:57,054 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/recompra/ano=2024/mes=08/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:04:57,075 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073741990_1166, replicas=172.18.0.2:9866 for /datalake/analytics/recompra/ano=2024/mes=08/dados.parquet
2025-12-03 00:04:57,104 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/recompra/ano=2024/mes=08/dados.parquet is closed by DFSClient_NONMAPREDUCE_257854605_170
2025-12-03 00:04:57,110 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/recompra/ano=2024/mes=09	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:04:57,125 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/recompra/ano=2024/mes=09/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:04:57,133 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073741991_1167, replicas=172.18.0.2:9866 for /datalake/analytics/recompra/ano=2024/mes=09/dados.parquet
2025-12-03 00:04:57,150 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - BLOCK* blk_1073741991_1167 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /datalake/analytics/recompra/ano=2024/mes=09/dados.parquet
2025-12-03 00:04:57,553 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/recompra/ano=2024/mes=09/dados.parquet is closed by DFSClient_NONMAPREDUCE_-1710645345_175
2025-12-03 00:04:57,562 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/recompra/ano=2024/mes=10	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:04:57,578 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/recompra/ano=2024/mes=10/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:04:57,597 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073741992_1168, replicas=172.18.0.2:9866 for /datalake/analytics/recompra/ano=2024/mes=10/dados.parquet
2025-12-03 00:04:57,626 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/recompra/ano=2024/mes=10/dados.parquet is closed by DFSClient_NONMAPREDUCE_-1414178898_181
2025-12-03 00:04:57,632 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/recompra/ano=2024/mes=11	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:04:57,647 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/recompra/ano=2024/mes=11/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:04:57,661 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073741993_1169, replicas=172.18.0.2:9866 for /datalake/analytics/recompra/ano=2024/mes=11/dados.parquet
2025-12-03 00:04:57,681 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - BLOCK* blk_1073741993_1169 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /datalake/analytics/recompra/ano=2024/mes=11/dados.parquet
2025-12-03 00:04:58,085 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/recompra/ano=2024/mes=11/dados.parquet is closed by DFSClient_NONMAPREDUCE_544308244_186
2025-12-03 00:04:58,095 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/recompra/ano=2024/mes=12	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:04:58,110 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/recompra/ano=2024/mes=12/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:04:58,132 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073741994_1170, replicas=172.18.0.2:9866 for /datalake/analytics/recompra/ano=2024/mes=12/dados.parquet
2025-12-03 00:04:58,155 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - BLOCK* blk_1073741994_1170 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /datalake/analytics/recompra/ano=2024/mes=12/dados.parquet
2025-12-03 00:04:58,558 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/recompra/ano=2024/mes=12/dados.parquet is closed by DFSClient_NONMAPREDUCE_1043046022_191
2025-12-03 00:04:58,567 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/recompra/ano=2025/mes=01	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:04:58,583 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/recompra/ano=2025/mes=01/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:04:58,588 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073741995_1171, replicas=172.18.0.2:9866 for /datalake/analytics/recompra/ano=2025/mes=01/dados.parquet
2025-12-03 00:04:58,086 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - BLOCK* blk_1073741995_1171 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /datalake/analytics/recompra/ano=2025/mes=01/dados.parquet
2025-12-03 00:04:58,489 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/recompra/ano=2025/mes=01/dados.parquet is closed by DFSClient_NONMAPREDUCE_-495100442_70
2025-12-03 00:04:58,497 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/recompra/ano=2025/mes=02	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:04:58,510 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/recompra/ano=2025/mes=02/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:04:58,514 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073741996_1172, replicas=172.18.0.2:9866 for /datalake/analytics/recompra/ano=2025/mes=02/dados.parquet
2025-12-03 00:04:58,522 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/recompra/ano=2025/mes=02/dados.parquet is closed by DFSClient_NONMAPREDUCE_894342891_80
2025-12-03 00:04:58,526 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/recompra/ano=2025/mes=03	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:04:58,538 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/recompra/ano=2025/mes=03/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:04:58,543 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073741997_1173, replicas=172.18.0.2:9866 for /datalake/analytics/recompra/ano=2025/mes=03/dados.parquet
2025-12-03 00:04:58,549 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - BLOCK* blk_1073741997_1173 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /datalake/analytics/recompra/ano=2025/mes=03/dados.parquet
2025-12-03 00:04:58,951 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/recompra/ano=2025/mes=03/dados.parquet is closed by DFSClient_NONMAPREDUCE_-2110140180_85
2025-12-03 00:04:58,959 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/recompra/ano=2025/mes=04	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:04:58,972 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/recompra/ano=2025/mes=04/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:04:58,975 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073741998_1174, replicas=172.18.0.2:9866 for /datalake/analytics/recompra/ano=2025/mes=04/dados.parquet
2025-12-03 00:04:58,983 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/recompra/ano=2025/mes=04/dados.parquet is closed by DFSClient_NONMAPREDUCE_-108176181_90
2025-12-03 00:04:58,987 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/recompra/ano=2025/mes=05	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:04:58,997 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/recompra/ano=2025/mes=05/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:04:59,002 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073741999_1175, replicas=172.18.0.2:9866 for /datalake/analytics/recompra/ano=2025/mes=05/dados.parquet
2025-12-03 00:04:59,009 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/recompra/ano=2025/mes=05/dados.parquet is closed by DFSClient_NONMAPREDUCE_1317240526_95
2025-12-03 00:04:59,014 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/recompra/ano=2025/mes=06	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:04:59,025 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/recompra/ano=2025/mes=06/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:04:59,029 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073742000_1176, replicas=172.18.0.2:9866 for /datalake/analytics/recompra/ano=2025/mes=06/dados.parquet
2025-12-03 00:04:59,036 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/recompra/ano=2025/mes=06/dados.parquet is closed by DFSClient_NONMAPREDUCE_1331033497_100
2025-12-03 00:04:59,041 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/recompra/ano=2025/mes=07	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:04:59,052 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/recompra/ano=2025/mes=07/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:04:59,056 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073742001_1177, replicas=172.18.0.2:9866 for /datalake/analytics/recompra/ano=2025/mes=07/dados.parquet
2025-12-03 00:04:59,064 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/recompra/ano=2025/mes=07/dados.parquet is closed by DFSClient_NONMAPREDUCE_2011614737_105
2025-12-03 00:04:59,069 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/recompra/ano=2025/mes=08	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:04:59,079 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/recompra/ano=2025/mes=08/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:04:59,083 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073742002_1178, replicas=172.18.0.2:9866 for /datalake/analytics/recompra/ano=2025/mes=08/dados.parquet
2025-12-03 00:04:59,092 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/recompra/ano=2025/mes=08/dados.parquet is closed by DFSClient_NONMAPREDUCE_-553803791_110
2025-12-03 00:04:59,097 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/recompra/ano=2025/mes=09	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:04:59,109 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/recompra/ano=2025/mes=09/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:04:59,113 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073742003_1179, replicas=172.18.0.2:9866 for /datalake/analytics/recompra/ano=2025/mes=09/dados.parquet
2025-12-03 00:04:59,121 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - BLOCK* blk_1073742003_1179 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /datalake/analytics/recompra/ano=2025/mes=09/dados.parquet
2025-12-03 00:04:59,524 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/recompra/ano=2025/mes=09/dados.parquet is closed by DFSClient_NONMAPREDUCE_722263266_115
2025-12-03 00:04:59,533 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/recompra/ano=2025/mes=10	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:04:59,546 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/recompra/ano=2025/mes=10/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:04:59,550 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073742004_1180, replicas=172.18.0.2:9866 for /datalake/analytics/recompra/ano=2025/mes=10/dados.parquet
2025-12-03 00:04:59,558 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - BLOCK* blk_1073742004_1180 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /datalake/analytics/recompra/ano=2025/mes=10/dados.parquet
2025-12-03 00:04:59,959 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/recompra/ano=2025/mes=10/dados.parquet is closed by DFSClient_NONMAPREDUCE_-318863522_120
2025-12-03 00:04:59,967 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/recompra/ano=2025/mes=11	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:04:59,982 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/recompra/ano=2025/mes=11/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:04:59,987 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073742005_1181, replicas=172.18.0.2:9866 for /datalake/analytics/recompra/ano=2025/mes=11/dados.parquet
2025-12-03 00:04:59,996 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/recompra/ano=2025/mes=11/dados.parquet is closed by DFSClient_NONMAPREDUCE_-728427374_125
2025-12-03 00:05:00,269 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/atrasos/ano=1970/mes=01	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:05:00,387 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/atrasos/ano=1970/mes=01/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:05:00,393 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073742006_1182, replicas=172.18.0.2:9866 for /datalake/analytics/atrasos/ano=1970/mes=01/dados.parquet
2025-12-03 00:05:00,427 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - BLOCK* blk_1073742006_1182 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /datalake/analytics/atrasos/ano=1970/mes=01/dados.parquet
2025-12-03 00:05:00,829 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/atrasos/ano=1970/mes=01/dados.parquet is closed by DFSClient_NONMAPREDUCE_244841029_130
2025-12-03 00:05:00,847 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/valor_30dias/ano=2023/mes=01	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:05:00,865 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/valor_30dias/ano=2023/mes=01/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:05:00,874 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073742007_1183, replicas=172.18.0.2:9866 for /datalake/analytics/valor_30dias/ano=2023/mes=01/dados.parquet
2025-12-03 00:05:00,897 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - BLOCK* blk_1073742007_1183 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /datalake/analytics/valor_30dias/ano=2023/mes=01/dados.parquet
2025-12-03 00:05:01,299 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/valor_30dias/ano=2023/mes=01/dados.parquet is closed by DFSClient_NONMAPREDUCE_-1328121683_135
2025-12-03 00:05:01,308 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/valor_30dias/ano=2023/mes=02	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:05:01,333 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/valor_30dias/ano=2023/mes=02/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:05:01,339 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073742008_1184, replicas=172.18.0.2:9866 for /datalake/analytics/valor_30dias/ano=2023/mes=02/dados.parquet
2025-12-03 00:05:01,355 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/valor_30dias/ano=2023/mes=02/dados.parquet is closed by DFSClient_NONMAPREDUCE_1834501262_140
2025-12-03 00:05:01,365 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/valor_30dias/ano=2023/mes=03	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:05:01,384 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/valor_30dias/ano=2023/mes=03/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:05:01,391 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073742009_1185, replicas=172.18.0.2:9866 for /datalake/analytics/valor_30dias/ano=2023/mes=03/dados.parquet
2025-12-03 00:05:01,405 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - BLOCK* blk_1073742009_1185 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /datalake/analytics/valor_30dias/ano=2023/mes=03/dados.parquet
2025-12-03 00:05:01,807 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/valor_30dias/ano=2023/mes=03/dados.parquet is closed by DFSClient_NONMAPREDUCE_-1051587560_145
2025-12-03 00:05:01,813 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/valor_30dias/ano=2023/mes=04	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:05:01,823 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/valor_30dias/ano=2023/mes=04/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:05:01,827 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073742010_1186, replicas=172.18.0.2:9866 for /datalake/analytics/valor_30dias/ano=2023/mes=04/dados.parquet
2025-12-03 00:05:01,835 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - BLOCK* blk_1073742010_1186 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /datalake/analytics/valor_30dias/ano=2023/mes=04/dados.parquet
2025-12-03 00:05:02,237 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/valor_30dias/ano=2023/mes=04/dados.parquet is closed by DFSClient_NONMAPREDUCE_-815665839_150
2025-12-03 00:05:02,243 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/valor_30dias/ano=2023/mes=05	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:05:02,256 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/valor_30dias/ano=2023/mes=05/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:05:02,259 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073742011_1187, replicas=172.18.0.2:9866 for /datalake/analytics/valor_30dias/ano=2023/mes=05/dados.parquet
2025-12-03 00:05:02,266 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - BLOCK* blk_1073742011_1187 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /datalake/analytics/valor_30dias/ano=2023/mes=05/dados.parquet
2025-12-03 00:05:02,667 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/valor_30dias/ano=2023/mes=05/dados.parquet is closed by DFSClient_NONMAPREDUCE_-5168637_155
2025-12-03 00:05:02,672 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/valor_30dias/ano=2023/mes=06	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:05:02,685 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/valor_30dias/ano=2023/mes=06/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:05:02,688 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073742012_1188, replicas=172.18.0.2:9866 for /datalake/analytics/valor_30dias/ano=2023/mes=06/dados.parquet
2025-12-03 00:05:02,697 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - BLOCK* blk_1073742012_1188 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /datalake/analytics/valor_30dias/ano=2023/mes=06/dados.parquet
2025-12-03 00:05:03,099 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/valor_30dias/ano=2023/mes=06/dados.parquet is closed by DFSClient_NONMAPREDUCE_-148700168_160
2025-12-03 00:05:03,106 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/valor_30dias/ano=2023/mes=07	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:05:03,116 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/valor_30dias/ano=2023/mes=07/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:05:03,121 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073742013_1189, replicas=172.18.0.2:9866 for /datalake/analytics/valor_30dias/ano=2023/mes=07/dados.parquet
2025-12-03 00:05:03,132 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - BLOCK* blk_1073742013_1189 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /datalake/analytics/valor_30dias/ano=2023/mes=07/dados.parquet
2025-12-03 00:05:03,534 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/valor_30dias/ano=2023/mes=07/dados.parquet is closed by DFSClient_NONMAPREDUCE_1169809523_165
2025-12-03 00:05:03,541 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/valor_30dias/ano=2023/mes=08	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:05:03,554 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/valor_30dias/ano=2023/mes=08/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:05:03,560 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073742014_1190, replicas=172.18.0.2:9866 for /datalake/analytics/valor_30dias/ano=2023/mes=08/dados.parquet
2025-12-03 00:05:03,569 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/valor_30dias/ano=2023/mes=08/dados.parquet is closed by DFSClient_NONMAPREDUCE_1653412156_170
2025-12-03 00:05:03,575 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/valor_30dias/ano=2023/mes=09	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:05:03,587 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/valor_30dias/ano=2023/mes=09/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:05:03,592 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073742015_1191, replicas=172.18.0.2:9866 for /datalake/analytics/valor_30dias/ano=2023/mes=09/dados.parquet
2025-12-03 00:05:03,600 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/valor_30dias/ano=2023/mes=09/dados.parquet is closed by DFSClient_NONMAPREDUCE_1936192820_175
2025-12-03 00:05:03,606 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/valor_30dias/ano=2023/mes=10	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:05:03,618 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/valor_30dias/ano=2023/mes=10/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:05:03,622 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073742016_1192, replicas=172.18.0.2:9866 for /datalake/analytics/valor_30dias/ano=2023/mes=10/dados.parquet
2025-12-03 00:05:03,631 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/valor_30dias/ano=2023/mes=10/dados.parquet is closed by DFSClient_NONMAPREDUCE_475164696_181
2025-12-03 00:05:03,636 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/valor_30dias/ano=2023/mes=11	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:05:03,648 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/valor_30dias/ano=2023/mes=11/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:05:03,652 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073742017_1193, replicas=172.18.0.2:9866 for /datalake/analytics/valor_30dias/ano=2023/mes=11/dados.parquet
2025-12-03 00:05:03,661 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - BLOCK* blk_1073742017_1193 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /datalake/analytics/valor_30dias/ano=2023/mes=11/dados.parquet
2025-12-03 00:05:04,063 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/valor_30dias/ano=2023/mes=11/dados.parquet is closed by DFSClient_NONMAPREDUCE_2094236756_186
2025-12-03 00:05:07,308 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/valor_30dias/ano=2023/mes=12	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:05:07,325 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/valor_30dias/ano=2023/mes=12/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:05:07,333 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073742018_1194, replicas=172.18.0.2:9866 for /datalake/analytics/valor_30dias/ano=2023/mes=12/dados.parquet
2025-12-03 00:05:07,343 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - BLOCK* blk_1073742018_1194 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /datalake/analytics/valor_30dias/ano=2023/mes=12/dados.parquet
2025-12-03 00:05:07,745 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/valor_30dias/ano=2023/mes=12/dados.parquet is closed by DFSClient_NONMAPREDUCE_1094192552_191
2025-12-03 00:05:07,751 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/valor_30dias/ano=2024/mes=01	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:05:07,763 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/valor_30dias/ano=2024/mes=01/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:05:07,766 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073742019_1195, replicas=172.18.0.2:9866 for /datalake/analytics/valor_30dias/ano=2024/mes=01/dados.parquet
2025-12-03 00:05:07,773 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - BLOCK* blk_1073742019_1195 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /datalake/analytics/valor_30dias/ano=2024/mes=01/dados.parquet
2025-12-03 00:05:08,175 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/valor_30dias/ano=2024/mes=01/dados.parquet is closed by DFSClient_NONMAPREDUCE_-1647431541_70
2025-12-03 00:05:08,180 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/valor_30dias/ano=2024/mes=02	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:05:08,191 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/valor_30dias/ano=2024/mes=02/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:05:08,195 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073742020_1196, replicas=172.18.0.2:9866 for /datalake/analytics/valor_30dias/ano=2024/mes=02/dados.parquet
2025-12-03 00:05:08,205 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/valor_30dias/ano=2024/mes=02/dados.parquet is closed by DFSClient_NONMAPREDUCE_-1551732586_80
2025-12-03 00:05:08,211 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/valor_30dias/ano=2024/mes=03	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:05:08,224 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/valor_30dias/ano=2024/mes=03/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:05:08,228 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073742021_1197, replicas=172.18.0.2:9866 for /datalake/analytics/valor_30dias/ano=2024/mes=03/dados.parquet
2025-12-03 00:05:08,240 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - BLOCK* blk_1073742021_1197 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /datalake/analytics/valor_30dias/ano=2024/mes=03/dados.parquet
2025-12-03 00:05:08,641 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/valor_30dias/ano=2024/mes=03/dados.parquet is closed by DFSClient_NONMAPREDUCE_-1551126868_85
2025-12-03 00:05:08,648 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/valor_30dias/ano=2024/mes=04	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:05:08,661 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/valor_30dias/ano=2024/mes=04/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:05:08,665 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073742022_1198, replicas=172.18.0.2:9866 for /datalake/analytics/valor_30dias/ano=2024/mes=04/dados.parquet
2025-12-03 00:05:08,672 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/valor_30dias/ano=2024/mes=04/dados.parquet is closed by DFSClient_NONMAPREDUCE_-1884076578_90
2025-12-03 00:05:08,678 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/valor_30dias/ano=2024/mes=05	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:05:08,689 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/valor_30dias/ano=2024/mes=05/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:05:08,694 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073742023_1199, replicas=172.18.0.2:9866 for /datalake/analytics/valor_30dias/ano=2024/mes=05/dados.parquet
2025-12-03 00:05:08,701 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - BLOCK* blk_1073742023_1199 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /datalake/analytics/valor_30dias/ano=2024/mes=05/dados.parquet
2025-12-03 00:05:09,105 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/valor_30dias/ano=2024/mes=05/dados.parquet is closed by DFSClient_NONMAPREDUCE_1047828747_95
2025-12-03 00:05:09,115 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/valor_30dias/ano=2024/mes=06	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:05:09,152 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/valor_30dias/ano=2024/mes=06/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:05:09,159 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073742024_1200, replicas=172.18.0.2:9866 for /datalake/analytics/valor_30dias/ano=2024/mes=06/dados.parquet
2025-12-03 00:05:09,180 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - BLOCK* blk_1073742024_1200 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /datalake/analytics/valor_30dias/ano=2024/mes=06/dados.parquet
2025-12-03 00:05:09,584 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/valor_30dias/ano=2024/mes=06/dados.parquet is closed by DFSClient_NONMAPREDUCE_-411691599_100
2025-12-03 00:05:09,591 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/valor_30dias/ano=2024/mes=07	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:05:09,605 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/valor_30dias/ano=2024/mes=07/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:05:09,610 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073742025_1201, replicas=172.18.0.2:9866 for /datalake/analytics/valor_30dias/ano=2024/mes=07/dados.parquet
2025-12-03 00:05:09,619 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/valor_30dias/ano=2024/mes=07/dados.parquet is closed by DFSClient_NONMAPREDUCE_-2065415207_105
2025-12-03 00:05:09,627 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/valor_30dias/ano=2024/mes=08	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:05:09,641 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/valor_30dias/ano=2024/mes=08/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:05:09,645 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073742026_1202, replicas=172.18.0.2:9866 for /datalake/analytics/valor_30dias/ano=2024/mes=08/dados.parquet
2025-12-03 00:05:09,652 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/valor_30dias/ano=2024/mes=08/dados.parquet is closed by DFSClient_NONMAPREDUCE_865939906_110
2025-12-03 00:05:09,658 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/valor_30dias/ano=2024/mes=09	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:05:09,669 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/valor_30dias/ano=2024/mes=09/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:05:09,675 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073742027_1203, replicas=172.18.0.2:9866 for /datalake/analytics/valor_30dias/ano=2024/mes=09/dados.parquet
2025-12-03 00:05:09,683 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/valor_30dias/ano=2024/mes=09/dados.parquet is closed by DFSClient_NONMAPREDUCE_1282931959_115
2025-12-03 00:05:09,689 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/valor_30dias/ano=2024/mes=10	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:05:09,701 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/valor_30dias/ano=2024/mes=10/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:05:09,705 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073742028_1204, replicas=172.18.0.2:9866 for /datalake/analytics/valor_30dias/ano=2024/mes=10/dados.parquet
2025-12-03 00:05:09,713 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/valor_30dias/ano=2024/mes=10/dados.parquet is closed by DFSClient_NONMAPREDUCE_400456953_120
2025-12-03 00:05:09,718 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/valor_30dias/ano=2024/mes=11	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:05:09,730 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/valor_30dias/ano=2024/mes=11/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:05:09,734 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073742029_1205, replicas=172.18.0.2:9866 for /datalake/analytics/valor_30dias/ano=2024/mes=11/dados.parquet
2025-12-03 00:05:09,741 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - BLOCK* blk_1073742029_1205 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /datalake/analytics/valor_30dias/ano=2024/mes=11/dados.parquet
2025-12-03 00:05:10,143 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/valor_30dias/ano=2024/mes=11/dados.parquet is closed by DFSClient_NONMAPREDUCE_1805702464_125
2025-12-03 00:05:10,149 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/valor_30dias/ano=2024/mes=12	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:05:10,163 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/valor_30dias/ano=2024/mes=12/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:05:10,169 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073742030_1206, replicas=172.18.0.2:9866 for /datalake/analytics/valor_30dias/ano=2024/mes=12/dados.parquet
2025-12-03 00:05:10,176 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - BLOCK* blk_1073742030_1206 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /datalake/analytics/valor_30dias/ano=2024/mes=12/dados.parquet
2025-12-03 00:05:10,578 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/valor_30dias/ano=2024/mes=12/dados.parquet is closed by DFSClient_NONMAPREDUCE_-1620527300_130
2025-12-03 00:05:10,590 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/valor_30dias/ano=2025/mes=01	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:05:10,608 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/valor_30dias/ano=2025/mes=01/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:05:10,613 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073742031_1207, replicas=172.18.0.2:9866 for /datalake/analytics/valor_30dias/ano=2025/mes=01/dados.parquet
2025-12-03 00:05:10,623 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - BLOCK* blk_1073742031_1207 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /datalake/analytics/valor_30dias/ano=2025/mes=01/dados.parquet
2025-12-03 00:05:11,025 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/valor_30dias/ano=2025/mes=01/dados.parquet is closed by DFSClient_NONMAPREDUCE_1843179278_135
2025-12-03 00:05:11,033 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/valor_30dias/ano=2025/mes=02	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:05:11,042 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/valor_30dias/ano=2025/mes=02/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:05:11,046 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073742032_1208, replicas=172.18.0.2:9866 for /datalake/analytics/valor_30dias/ano=2025/mes=02/dados.parquet
2025-12-03 00:05:11,052 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - BLOCK* blk_1073742032_1208 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /datalake/analytics/valor_30dias/ano=2025/mes=02/dados.parquet
2025-12-03 00:05:11,454 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/valor_30dias/ano=2025/mes=02/dados.parquet is closed by DFSClient_NONMAPREDUCE_-1352917493_140
2025-12-03 00:05:11,461 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/valor_30dias/ano=2025/mes=03	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:05:11,473 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/valor_30dias/ano=2025/mes=03/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:05:11,477 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073742033_1209, replicas=172.18.0.2:9866 for /datalake/analytics/valor_30dias/ano=2025/mes=03/dados.parquet
2025-12-03 00:05:11,483 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - BLOCK* blk_1073742033_1209 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /datalake/analytics/valor_30dias/ano=2025/mes=03/dados.parquet
2025-12-03 00:05:11,884 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/valor_30dias/ano=2025/mes=03/dados.parquet is closed by DFSClient_NONMAPREDUCE_622433448_145
2025-12-03 00:05:11,892 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/valor_30dias/ano=2025/mes=04	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:05:11,902 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/valor_30dias/ano=2025/mes=04/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:05:11,905 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073742034_1210, replicas=172.18.0.2:9866 for /datalake/analytics/valor_30dias/ano=2025/mes=04/dados.parquet
2025-12-03 00:05:11,914 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - BLOCK* blk_1073742034_1210 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /datalake/analytics/valor_30dias/ano=2025/mes=04/dados.parquet
2025-12-03 00:05:12,316 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/valor_30dias/ano=2025/mes=04/dados.parquet is closed by DFSClient_NONMAPREDUCE_-1750634718_150
2025-12-03 00:05:12,322 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/valor_30dias/ano=2025/mes=05	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:05:12,332 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/valor_30dias/ano=2025/mes=05/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:05:12,336 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073742035_1211, replicas=172.18.0.2:9866 for /datalake/analytics/valor_30dias/ano=2025/mes=05/dados.parquet
2025-12-03 00:05:12,341 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - BLOCK* blk_1073742035_1211 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /datalake/analytics/valor_30dias/ano=2025/mes=05/dados.parquet
2025-12-03 00:05:12,743 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/valor_30dias/ano=2025/mes=05/dados.parquet is closed by DFSClient_NONMAPREDUCE_1746702386_155
2025-12-03 00:05:12,748 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/valor_30dias/ano=2025/mes=06	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:05:12,757 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/valor_30dias/ano=2025/mes=06/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:05:12,760 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073742036_1212, replicas=172.18.0.2:9866 for /datalake/analytics/valor_30dias/ano=2025/mes=06/dados.parquet
2025-12-03 00:05:12,767 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - BLOCK* blk_1073742036_1212 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /datalake/analytics/valor_30dias/ano=2025/mes=06/dados.parquet
2025-12-03 00:05:13,169 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/valor_30dias/ano=2025/mes=06/dados.parquet is closed by DFSClient_NONMAPREDUCE_1820057832_160
2025-12-03 00:05:13,176 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/valor_30dias/ano=2025/mes=07	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:05:13,193 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/valor_30dias/ano=2025/mes=07/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:05:13,201 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073742037_1213, replicas=172.18.0.2:9866 for /datalake/analytics/valor_30dias/ano=2025/mes=07/dados.parquet
2025-12-03 00:05:13,210 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/valor_30dias/ano=2025/mes=07/dados.parquet is closed by DFSClient_NONMAPREDUCE_209593064_165
2025-12-03 00:05:13,216 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/valor_30dias/ano=2025/mes=08	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:05:13,234 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/valor_30dias/ano=2025/mes=08/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:05:13,240 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073742038_1214, replicas=172.18.0.2:9866 for /datalake/analytics/valor_30dias/ano=2025/mes=08/dados.parquet
2025-12-03 00:05:13,250 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - BLOCK* blk_1073742038_1214 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /datalake/analytics/valor_30dias/ano=2025/mes=08/dados.parquet
2025-12-03 00:05:13,652 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/valor_30dias/ano=2025/mes=08/dados.parquet is closed by DFSClient_NONMAPREDUCE_1696912025_170
2025-12-03 00:05:13,660 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/valor_30dias/ano=2025/mes=09	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:05:13,670 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/valor_30dias/ano=2025/mes=09/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:05:13,675 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073742039_1215, replicas=172.18.0.2:9866 for /datalake/analytics/valor_30dias/ano=2025/mes=09/dados.parquet
2025-12-03 00:05:13,682 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - BLOCK* blk_1073742039_1215 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /datalake/analytics/valor_30dias/ano=2025/mes=09/dados.parquet
2025-12-03 00:05:14,085 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/valor_30dias/ano=2025/mes=09/dados.parquet is closed by DFSClient_NONMAPREDUCE_-146493564_175
2025-12-03 00:05:14,091 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/valor_30dias/ano=2025/mes=10	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:05:14,100 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/valor_30dias/ano=2025/mes=10/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:05:14,105 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073742040_1216, replicas=172.18.0.2:9866 for /datalake/analytics/valor_30dias/ano=2025/mes=10/dados.parquet
2025-12-03 00:05:14,113 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/valor_30dias/ano=2025/mes=10/dados.parquet is closed by DFSClient_NONMAPREDUCE_-1248580262_181
2025-12-03 00:05:14,120 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.7	cmd=mkdirs	src=/datalake/analytics/valor_30dias/ano=2025/mes=11	dst=null	perm=root:supergroup:rwxr-xr-x	proto=webhdfs
2025-12-03 00:05:14,133 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.2	cmd=create	src=/datalake/analytics/valor_30dias/ano=2025/mes=11/dados.parquet	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2025-12-03 00:05:14,137 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* allocate blk_1073742041_1217, replicas=172.18.0.2:9866 for /datalake/analytics/valor_30dias/ano=2025/mes=11/dados.parquet
2025-12-03 00:05:14,146 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - BLOCK* blk_1073742041_1217 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /datalake/analytics/valor_30dias/ano=2025/mes=11/dados.parquet
2025-12-03 00:05:14,547 INFO org.apache.hadoop.hdfs.StateChange - DIR* completeFile: /datalake/analytics/valor_30dias/ano=2025/mes=11/dados.parquet is closed by DFSClient_NONMAPREDUCE_-742984459_186
2025-12-03 00:10:22,169 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.3	cmd=getfileinfo	src=/datalake/analytics/recompra	dst=null	perm=null	proto=rpc
2025-12-03 00:10:22,189 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.3	cmd=listStatus	src=/datalake/analytics/recompra	dst=null	perm=null	proto=rpc
2025-12-03 00:11:07,820 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.3	cmd=getfileinfo	src=/datalake/analytics/recompra/ano=2025/mes=12	dst=null	perm=null	proto=rpc
