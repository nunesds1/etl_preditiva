2025-12-02 23:13:42,771 INFO org.apache.hadoop.hdfs.server.namenode.NameNode - STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = namenode/172.18.0.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.3.6
STARTUP_MSG:   classpath = /opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/curator-framework-5.2.0.jar:/opt/hadoop/share/hadoop/common/lib/jersey-core-1.19.4.jar:/opt/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/opt/hadoop/share/hadoop/common/lib/commons-net-3.9.0.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jackson-annotations-2.12.7.jar:/opt/hadoop/share/hadoop/common/lib/jetty-server-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-http2-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-lang3-3.12.0.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-classes-epoll-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/httpcore-4.4.13.jar:/opt/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-handler-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/common/lib/jackson-core-2.12.7.jar:/opt/hadoop/share/hadoop/common/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-udt-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jersey-json-1.20.jar:/opt/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-native-unix-common-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/netty-common-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/commons-codec-1.15.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-stomp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.4.jar:/opt/hadoop/share/hadoop/common/lib/commons-configuration2-2.8.0.jar:/opt/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/hadoop/common/lib/netty-handler-proxy-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/hadoop/common/lib/jetty-util-ajax-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-annotations-3.3.6.jar:/opt/hadoop/share/hadoop/common/lib/jetty-security-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jetty-io-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-native-epoll-4.1.89.Final-linux-aarch_64.jar:/opt/hadoop/share/hadoop/common/lib/commons-text-1.10.0.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-xml-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-all-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-resolver-dns-classes-macos-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jetty-http-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jsr305-3.0.2.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-mqtt-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-resolver-dns-native-macos-4.1.89.Final-osx-aarch_64.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-auth-3.3.6.jar:/opt/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop/share/hadoop/common/lib/jetty-webapp-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/zookeeper-3.6.3.jar:/opt/hadoop/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop/share/hadoop/common/lib/gson-2.9.0.jar:/opt/hadoop/share/hadoop/common/lib/jsch-0.1.55.jar:/opt/hadoop/share/hadoop/common/lib/failureaccess-1.0.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-native-epoll-4.1.89.Final-linux-x86_64.jar:/opt/hadoop/share/hadoop/common/lib/httpclient-4.5.13.jar:/opt/hadoop/share/hadoop/common/lib/netty-resolver-dns-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-resolver-dns-native-macos-4.1.89.Final-osx-x86_64.jar:/opt/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/hadoop/common/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-handler-ssl-ocsp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-dns-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/curator-recipes-5.2.0.jar:/opt/hadoop/share/hadoop/common/lib/commons-compress-1.21.jar:/opt/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-native-kqueue-4.1.89.Final-osx-aarch_64.jar:/opt/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/hadoop/common/lib/jetty-util-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/checker-qual-2.5.2.jar:/opt/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar:/opt/hadoop/share/hadoop/common/lib/jetty-xml-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/jersey-server-1.19.4.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-redis-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-memcache-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-classes-kqueue-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/zookeeper-jute-3.6.3.jar:/opt/hadoop/share/hadoop/common/lib/jackson-databind-2.12.7.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-rxtx-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-smtp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/common/lib/jetty-servlet-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/common/lib/commons-io-2.8.0.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-socks-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-http-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-native-kqueue-4.1.89.Final-osx-x86_64.jar:/opt/hadoop/share/hadoop/common/lib/netty-codec-haproxy-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/hadoop/common/lib/reload4j-1.2.22.jar:/opt/hadoop/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/hadoop/common/lib/netty-resolver-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/curator-client-5.2.0.jar:/opt/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/opt/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.36.jar:/opt/hadoop/share/hadoop/common/lib/netty-buffer-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/hadoop/common/lib/jettison-1.5.4.jar:/opt/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/netty-transport-sctp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/hadoop/common/hadoop-common-3.3.6-tests.jar:/opt/hadoop/share/hadoop/common/hadoop-kms-3.3.6.jar:/opt/hadoop/share/hadoop/common/hadoop-nfs-3.3.6.jar:/opt/hadoop/share/hadoop/common/hadoop-registry-3.3.6.jar:/opt/hadoop/share/hadoop/common/hadoop-common-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/curator-framework-5.2.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/jakarta.activation-api-1.2.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-net-3.9.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.12.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-server-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-http2-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.12.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/okio-2.8.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-epoll-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-handler-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-core-2.12.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-udt-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-json-1.20.jar:/opt/hadoop/share/hadoop/hdfs/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-native-unix-common-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-common-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-codec-1.15.jar:/opt/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-stomp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.8.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-3.10.6.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/HikariCP-java7-2.4.12.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-common-1.4.10.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-handler-proxy-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-security-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-io-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.89.Final-linux-aarch_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-text-1.10.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-xml-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-all-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-classes-macos-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/okhttp-4.9.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-http-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kotlin-stdlib-1.4.10.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-mqtt-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.89.Final-osx-aarch_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/zookeeper-3.6.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/opt/hadoop/share/hadoop/hdfs/lib/gson-2.9.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsch-0.1.55.jar:/opt/hadoop/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-native-epoll-4.1.89.Final-linux-x86_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-resolver-dns-native-macos-4.1.89.Final-osx-x86_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-handler-ssl-ocsp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-dns-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/curator-recipes-5.2.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-compress-1.21.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.89.Final-osx-aarch_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-util-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-redis-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-memcache-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-classes-kqueue-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/zookeeper-jute-3.6.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.12.7.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-rxtx-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-smtp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-io-2.8.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-socks-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-http-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-native-kqueue-4.1.89.Final-osx-x86_64.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-codec-haproxy-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/reload4j-1.2.22.jar:/opt/hadoop/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-resolver-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/curator-client-5.2.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-buffer-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jettison-1.5.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-transport-sctp-4.1.89.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.3.6-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.6-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.6-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.3.6.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.3.6-tests.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.3.6-tests.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.3.6.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.3.6.jar:/opt/hadoop/share/hadoop/yarn:/opt/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.12.7.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-plus-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/jline-3.9.0.jar:/opt/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-annotations-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/websocket-api-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/asm-tree-9.4.jar:/opt/hadoop/share/hadoop/yarn/lib/bcpkix-jdk15on-1.68.jar:/opt/hadoop/share/hadoop/yarn/lib/javax.websocket-client-api-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-client-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/asm-commons-9.4.jar:/opt/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jna-5.2.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jetty-jndi-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/opt/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/opt/hadoop/share/hadoop/yarn/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.12.7.jar:/opt/hadoop/share/hadoop/yarn/lib/objenesis-2.6.jar:/opt/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop/share/hadoop/yarn/lib/snakeyaml-2.0.jar:/opt/hadoop/share/hadoop/yarn/lib/javax.websocket-api-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/javax-websocket-server-impl-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/websocket-servlet-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.4.jar:/opt/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/opt/hadoop/share/hadoop/yarn/lib/websocket-common-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop/share/hadoop/yarn/lib/bcprov-jdk15on-1.68.jar:/opt/hadoop/share/hadoop/yarn/lib/javax-websocket-client-impl-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.12.7.jar:/opt/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.4.jar:/opt/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/opt/hadoop/share/hadoop/yarn/lib/websocket-client-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/lib/websocket-server-9.4.51.v20230217.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-mawo-core-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.3.6.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.3.6.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r 1be78238728da9266a4f88195058f08fd012bf9c; compiled by 'ubuntu' on 2023-06-18T08:22Z
STARTUP_MSG:   java = 11.0.29
************************************************************/
2025-12-02 23:13:42,780 INFO org.apache.hadoop.hdfs.server.namenode.NameNode - registered UNIX signal handlers for [TERM, HUP, INT]
2025-12-02 23:13:42,887 INFO org.apache.hadoop.hdfs.server.namenode.NameNode - createNameNode []
2025-12-02 23:13:42,998 WARN org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-namenode.properties,hadoop-metrics2.properties
2025-12-02 23:13:43,158 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2025-12-02 23:13:43,158 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl - NameNode metrics system started
2025-12-02 23:13:43,181 INFO org.apache.hadoop.hdfs.server.namenode.NameNodeUtils - fs.defaultFS is hdfs://namenode:9000
2025-12-02 23:13:43,181 INFO org.apache.hadoop.hdfs.server.namenode.NameNode - Clients should use namenode:9000 to access this namenode/service.
2025-12-02 23:13:43,377 INFO org.apache.hadoop.util.JvmPauseMonitor - Starting JVM pause monitor
2025-12-02 23:13:43,429 INFO org.apache.hadoop.hdfs.DFSUtil - Filter initializers set : org.apache.hadoop.http.lib.StaticUserWebFilter,org.apache.hadoop.hdfs.web.AuthFilterInitializer
2025-12-02 23:13:43,441 INFO org.apache.hadoop.hdfs.DFSUtil - Starting Web-server for hdfs at: http://0.0.0.0:9870
2025-12-02 23:13:43,461 INFO org.eclipse.jetty.util.log - Logging initialized @1525ms to org.eclipse.jetty.util.log.Slf4jLog
2025-12-02 23:13:43,607 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-12-02 23:13:43,623 INFO org.apache.hadoop.http.HttpRequestLog - Http request log for http.requests.namenode is not defined
2025-12-02 23:13:43,632 INFO org.apache.hadoop.http.HttpServer2 - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2025-12-02 23:13:43,635 INFO org.apache.hadoop.http.HttpServer2 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2025-12-02 23:13:43,635 INFO org.apache.hadoop.http.HttpServer2 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2025-12-02 23:13:43,635 INFO org.apache.hadoop.http.HttpServer2 - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2025-12-02 23:13:43,639 INFO org.apache.hadoop.http.HttpServer2 - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context hdfs
2025-12-02 23:13:43,639 INFO org.apache.hadoop.http.HttpServer2 - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context logs
2025-12-02 23:13:43,639 INFO org.apache.hadoop.http.HttpServer2 - Added filter AuthFilter (class=org.apache.hadoop.hdfs.web.AuthFilter) to context static
2025-12-02 23:13:43,683 INFO org.apache.hadoop.http.HttpServer2 - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2025-12-02 23:13:43,703 INFO org.apache.hadoop.http.HttpServer2 - Jetty bound to port 9870
2025-12-02 23:13:43,704 INFO org.eclipse.jetty.server.Server - jetty-9.4.51.v20230217; built: 2023-02-17T08:19:37.309Z; git: b45c405e4544384de066f814ed42ae3dceacdd49; jvm 11.0.29+7-post-Ubuntu-1ubuntu122.04
2025-12-02 23:13:43,731 INFO org.eclipse.jetty.server.session - DefaultSessionIdManager workerName=node0
2025-12-02 23:13:43,731 INFO org.eclipse.jetty.server.session - No SessionScavenger set, using defaults
2025-12-02 23:13:43,733 INFO org.eclipse.jetty.server.session - node0 Scavenging every 660000ms
2025-12-02 23:13:43,753 WARN org.apache.hadoop.security.authentication.server.AuthenticationFilter - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /root/hadoop-http-auth-signature-secret
2025-12-02 23:13:43,757 INFO org.eclipse.jetty.server.handler.ContextHandler - Started o.e.j.s.ServletContextHandler@3e14c16d{logs,/logs,file:///opt/hadoop/logs/,AVAILABLE}
2025-12-02 23:13:43,758 INFO org.eclipse.jetty.server.handler.ContextHandler - Started o.e.j.s.ServletContextHandler@793138bd{static,/static,file:///opt/hadoop/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2025-12-02 23:13:43,881 INFO org.eclipse.jetty.server.handler.ContextHandler - Started o.e.j.w.WebAppContext@64da2a7{hdfs,/,file:///opt/hadoop/share/hadoop/hdfs/webapps/hdfs/,AVAILABLE}{file:/opt/hadoop/share/hadoop/hdfs/webapps/hdfs}
2025-12-02 23:13:43,897 INFO org.eclipse.jetty.server.AbstractConnector - Started ServerConnector@62163b39{HTTP/1.1, (http/1.1)}{0.0.0.0:9870}
2025-12-02 23:13:43,898 INFO org.eclipse.jetty.server.Server - Started @1961ms
real-time non-blocking time  (microseconds, -R) unlimited
core file size              (blocks, -c) 0
data seg size               (kbytes, -d) unlimited
scheduling priority                 (-e) 0
file size                   (blocks, -f) unlimited
pending signals                     (-i) 31101
max locked memory           (kbytes, -l) unlimited
max memory size             (kbytes, -m) unlimited
open files                          (-n) 1048576
pipe size                (512 bytes, -p) 8
POSIX message queues         (bytes, -q) 819200
real-time priority                  (-r) 0
stack size                  (kbytes, -s) 8192
cpu time                   (seconds, -t) unlimited
max user processes                  (-u) unlimited
virtual memory              (kbytes, -v) unlimited
file locks                          (-x) unlimited
2025-12-02 23:13:44,122 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem - Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
2025-12-02 23:13:44,122 WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem - Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
2025-12-02 23:13:44,197 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog - Edit logging is async:true
2025-12-02 23:13:44,291 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - KeyProvider: null
2025-12-02 23:13:44,294 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - fsLock is fair: true
2025-12-02 23:13:44,294 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - Detailed lock hold time metrics enabled: false
2025-12-02 23:13:44,317 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - fsOwner                = root (auth:SIMPLE)
2025-12-02 23:13:44,318 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - supergroup             = supergroup
2025-12-02 23:13:44,318 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - isPermissionEnabled    = true
2025-12-02 23:13:44,318 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - isStoragePolicyEnabled = true
2025-12-02 23:13:44,318 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - HA Enabled: false
2025-12-02 23:13:44,369 INFO org.apache.hadoop.hdfs.server.common.Util - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2025-12-02 23:13:44,803 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager - dfs.block.invalidate.limit : configured=1000, counted=60, effected=1000
2025-12-02 23:13:44,804 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager - dfs.namenode.datanode.registration.ip-hostname-check=true
2025-12-02 23:13:44,808 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2025-12-02 23:13:44,809 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager - The block deletion will start around 2025 Dec 02 23:13:44
2025-12-02 23:13:44,813 INFO org.apache.hadoop.util.GSet - Computing capacity for map BlocksMap
2025-12-02 23:13:44,813 INFO org.apache.hadoop.util.GSet - VM type       = 64-bit
2025-12-02 23:13:44,815 INFO org.apache.hadoop.util.GSet - 2.0% max memory 1.9 GB = 39.0 MB
2025-12-02 23:13:44,815 INFO org.apache.hadoop.util.GSet - capacity      = 2^22 = 4194304 entries
2025-12-02 23:13:44,841 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager - Storage policy satisfier is disabled
2025-12-02 23:13:44,841 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager - dfs.block.access.token.enable = false
2025-12-02 23:13:44,854 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode - dfs.namenode.safemode.threshold-pct = 0.999
2025-12-02 23:13:44,854 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode - dfs.namenode.safemode.min.datanodes = 0
2025-12-02 23:13:44,854 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode - dfs.namenode.safemode.extension = 30000
2025-12-02 23:13:44,856 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager - defaultReplication         = 1
2025-12-02 23:13:44,856 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager - maxReplication             = 512
2025-12-02 23:13:44,856 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager - minReplication             = 1
2025-12-02 23:13:44,856 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager - maxReplicationStreams      = 2
2025-12-02 23:13:44,856 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager - redundancyRecheckInterval  = 3000ms
2025-12-02 23:13:44,856 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager - encryptDataTransfer        = false
2025-12-02 23:13:44,857 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager - maxNumBlocksToLog          = 1000
2025-12-02 23:13:44,933 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory - GLOBAL serial map: bits=29 maxEntries=536870911
2025-12-02 23:13:44,933 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory - USER serial map: bits=24 maxEntries=16777215
2025-12-02 23:13:44,933 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory - GROUP serial map: bits=24 maxEntries=16777215
2025-12-02 23:13:44,933 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory - XATTR serial map: bits=24 maxEntries=16777215
2025-12-02 23:13:44,959 INFO org.apache.hadoop.util.GSet - Computing capacity for map INodeMap
2025-12-02 23:13:44,959 INFO org.apache.hadoop.util.GSet - VM type       = 64-bit
2025-12-02 23:13:44,959 INFO org.apache.hadoop.util.GSet - 1.0% max memory 1.9 GB = 19.5 MB
2025-12-02 23:13:44,959 INFO org.apache.hadoop.util.GSet - capacity      = 2^21 = 2097152 entries
2025-12-02 23:13:44,969 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory - ACLs enabled? true
2025-12-02 23:13:44,969 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory - POSIX ACL inheritance enabled? true
2025-12-02 23:13:44,969 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory - XAttrs enabled? true
2025-12-02 23:13:44,969 INFO org.apache.hadoop.hdfs.server.namenode.NameNode - Caching file names occurring more than 10 times
2025-12-02 23:13:44,974 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2025-12-02 23:13:44,976 INFO org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager - SkipList is disabled
2025-12-02 23:13:44,981 INFO org.apache.hadoop.util.GSet - Computing capacity for map cachedBlocks
2025-12-02 23:13:44,981 INFO org.apache.hadoop.util.GSet - VM type       = 64-bit
2025-12-02 23:13:44,981 INFO org.apache.hadoop.util.GSet - 0.25% max memory 1.9 GB = 4.9 MB
2025-12-02 23:13:44,981 INFO org.apache.hadoop.util.GSet - capacity      = 2^19 = 524288 entries
2025-12-02 23:13:44,994 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2025-12-02 23:13:44,994 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics - NNTop conf: dfs.namenode.top.num.users = 10
2025-12-02 23:13:44,994 INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2025-12-02 23:13:45,000 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - Retry cache on namenode is enabled
2025-12-02 23:13:45,000 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2025-12-02 23:13:45,007 INFO org.apache.hadoop.util.GSet - Computing capacity for map NameNodeRetryCache
2025-12-02 23:13:45,007 INFO org.apache.hadoop.util.GSet - VM type       = 64-bit
2025-12-02 23:13:45,008 INFO org.apache.hadoop.util.GSet - 0.029999999329447746% max memory 1.9 GB = 598.4 KB
2025-12-02 23:13:45,008 INFO org.apache.hadoop.util.GSet - capacity      = 2^16 = 65536 entries
2025-12-02 23:13:45,060 INFO org.apache.hadoop.hdfs.server.common.Storage - Lock on /opt/hadoop/data/nn/in_use.lock acquired by nodename 121@namenode
2025-12-02 23:13:45,101 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager - Recovering unfinalized segments in /opt/hadoop/data/nn/current
2025-12-02 23:13:45,155 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager - Finalizing edits file /opt/hadoop/data/nn/current/edits_inprogress_0000000000000000990 -> /opt/hadoop/data/nn/current/edits_0000000000000000990-0000000000000000990
2025-12-02 23:13:45,193 INFO org.apache.hadoop.hdfs.server.namenode.FSImage - Planning to load image: FSImageFile(file=/opt/hadoop/data/nn/current/fsimage_0000000000000000989, cpktTxId=0000000000000000989)
2025-12-02 23:13:45,368 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode - Loading 156 INodes.
2025-12-02 23:13:45,419 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode - Successfully loaded 156 inodes
2025-12-02 23:13:45,451 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode - Completed update blocks map and name cache, total waiting duration 1ms.
2025-12-02 23:13:45,466 INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf - Loaded FSImage in 0 seconds.
2025-12-02 23:13:45,466 INFO org.apache.hadoop.hdfs.server.namenode.FSImage - Loaded image for txid 989 from /opt/hadoop/data/nn/current/fsimage_0000000000000000989
2025-12-02 23:13:45,472 INFO org.apache.hadoop.hdfs.server.namenode.FSImage - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@27a7ef08 expecting start txid #990
2025-12-02 23:13:45,473 INFO org.apache.hadoop.hdfs.server.namenode.FSImage - Start loading edits file /opt/hadoop/data/nn/current/edits_0000000000000000990-0000000000000000990 maxTxnsToRead = 9223372036854775807
2025-12-02 23:13:45,476 INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream - Fast-forwarding stream '/opt/hadoop/data/nn/current/edits_0000000000000000990-0000000000000000990' to transaction ID 990
2025-12-02 23:13:45,570 INFO org.apache.hadoop.hdfs.server.namenode.FSImage - Loaded 1 edits file(s) (the last named /opt/hadoop/data/nn/current/edits_0000000000000000990-0000000000000000990) of total size 1048576.0, total edits 1.0, total load time 32.0 ms
2025-12-02 23:13:45,570 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2025-12-02 23:13:45,574 INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog - Starting log segment at 991
2025-12-02 23:13:45,709 INFO org.apache.hadoop.hdfs.server.namenode.NameCache - initialized with 1 entries 71 lookups
2025-12-02 23:13:45,709 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - Finished loading FSImage in 696 msecs
2025-12-02 23:13:46,067 INFO org.apache.hadoop.hdfs.server.namenode.NameNode - RPC server is binding to namenode:9000
2025-12-02 23:13:46,067 INFO org.apache.hadoop.hdfs.server.namenode.NameNode - Enable NameNode state context:false
2025-12-02 23:13:46,082 INFO org.apache.hadoop.ipc.CallQueueManager - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2025-12-02 23:13:46,114 INFO org.apache.hadoop.ipc.Server - Listener at namenode:9000
2025-12-02 23:13:46,115 INFO org.apache.hadoop.ipc.Server - Starting Socket Reader #1 for port 9000
2025-12-02 23:13:46,295 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2025-12-02 23:13:46,319 INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager - Number of blocks under construction: 0
2025-12-02 23:13:46,347 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeAdminDefaultMonitor - Initialized the Default Decommission and Maintenance monitor
2025-12-02 23:13:46,353 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager - Start MarkedDeleteBlockScrubber thread
2025-12-02 23:13:46,362 INFO org.apache.hadoop.hdfs.StateChange - STATE* Safe mode ON. 
The reported blocks 0 needs additional 71 blocks to reach the threshold 0.9990 of total blocks 72.
The minimum number of live datanodes is not required. Safe mode will be turned off automatically once the thresholds have been reached.
2025-12-02 23:13:46,420 INFO org.apache.hadoop.ipc.Server - IPC Server Responder: starting
2025-12-02 23:13:46,423 INFO org.apache.hadoop.ipc.Server - IPC Server listener on 9000: starting
2025-12-02 23:13:46,431 INFO org.apache.hadoop.hdfs.server.namenode.NameNode - NameNode RPC up at: namenode/172.18.0.4:9000
2025-12-02 23:13:46,434 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem - Starting services required for active state
2025-12-02 23:13:46,434 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory - Initializing quota with 12 thread(s)
2025-12-02 23:13:46,484 INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory - Quota initialization completed in 50 milliseconds
name space=156
storage space=8352913
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2025-12-02 23:13:46,499 INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor - Starting CacheReplicationMonitor with interval 30000 milliseconds
2025-12-02 23:13:47,875 INFO org.apache.hadoop.hdfs.StateChange - BLOCK* registerDatanode: from DatanodeRegistration(172.18.0.2:9866, datanodeUuid=d02fd027-40dc-452a-aa59-17a9b2edb3fe, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-8de1d889-312c-47f1-9135-cecbc5761ae6;nsid=1122154000;c=1763416835540) storage d02fd027-40dc-452a-aa59-17a9b2edb3fe
2025-12-02 23:13:47,878 INFO org.apache.hadoop.net.NetworkTopology - Adding a new node: /default-rack/172.18.0.2:9866
2025-12-02 23:13:47,879 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager - Registered DN d02fd027-40dc-452a-aa59-17a9b2edb3fe (172.18.0.2:9866).
2025-12-02 23:13:47,993 INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor - Adding new storage ID DS-4f9c54b4-f4d4-4ee3-b0b9-9580107a8e16 for DN 172.18.0.2:9866
2025-12-02 23:13:48,050 INFO BlockStateChange - BLOCK* processReport 0x45779e7798f2abc8 with lease ID 0xbdc3798b29bdcd81: Processing first storage report for DS-4f9c54b4-f4d4-4ee3-b0b9-9580107a8e16 from datanode DatanodeRegistration(172.18.0.2:9866, datanodeUuid=d02fd027-40dc-452a-aa59-17a9b2edb3fe, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-8de1d889-312c-47f1-9135-cecbc5761ae6;nsid=1122154000;c=1763416835540)
2025-12-02 23:13:48,057 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager - initializing replication queues
2025-12-02 23:13:48,059 INFO org.apache.hadoop.hdfs.StateChange - STATE* Safe mode extension entered. 
The reported blocks 71 has reached the threshold 0.9990 of total blocks 72. The minimum number of live datanodes is not required. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
2025-12-02 23:13:48,063 INFO BlockStateChange - BLOCK* processReport 0x45779e7798f2abc8 with lease ID 0xbdc3798b29bdcd81: from storage DS-4f9c54b4-f4d4-4ee3-b0b9-9580107a8e16 node DatanodeRegistration(172.18.0.2:9866, datanodeUuid=d02fd027-40dc-452a-aa59-17a9b2edb3fe, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-8de1d889-312c-47f1-9135-cecbc5761ae6;nsid=1122154000;c=1763416835540), blocks: 72, hasStaleStorage: false, processing time: 12 msecs, invalidatedBlocks: 0
2025-12-02 23:13:48,077 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager - Total number of blocks            = 72
2025-12-02 23:13:48,077 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager - Number of invalid blocks          = 0
2025-12-02 23:13:48,077 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager - Number of under-replicated blocks = 0
2025-12-02 23:13:48,077 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager - Number of  over-replicated blocks = 0
2025-12-02 23:13:48,077 INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager - Number of blocks being written    = 0
2025-12-02 23:13:48,077 INFO org.apache.hadoop.hdfs.StateChange - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 19 msec
Dec 02, 2025 11:14:06 PM com.sun.jersey.api.core.PackagesResourceConfig init
INFO: Scanning for root resource and provider classes in the packages:
  org.apache.hadoop.hdfs.server.namenode.web.resources
  org.apache.hadoop.hdfs.web.resources
Dec 02, 2025 11:14:07 PM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Root resource classes found:
  class org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods
Dec 02, 2025 11:14:07 PM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Provider classes found:
  class org.apache.hadoop.hdfs.web.resources.ExceptionHandler
  class org.apache.hadoop.hdfs.web.resources.UserProvider
Dec 02, 2025 11:14:07 PM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19.4 05/24/2017 03:20 PM'
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by com.sun.xml.bind.v2.runtime.reflect.opt.Injector$1 (file:/opt/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar) to method java.lang.ClassLoader.defineClass(java.lang.String,byte[],int,int)
WARNING: Please consider reporting this to the maintainers of com.sun.xml.bind.v2.runtime.reflect.opt.Injector$1
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
Dec 02, 2025 11:14:07 PM com.sun.jersey.spi.inject.Errors processErrorMessages
WARNING: The following warnings have been detected with resource and/or provider classes:
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.getRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.GetOpParam,org.apache.hadoop.hdfs.web.resources.OffsetParam,org.apache.hadoop.hdfs.web.resources.LengthParam,org.apache.hadoop.hdfs.web.resources.RenewerParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,java.util.List,org.apache.hadoop.hdfs.web.resources.XAttrEncodingParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.FsActionParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.TokenKindParam,org.apache.hadoop.hdfs.web.resources.TokenServiceParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StartAfterParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.putRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PutOpParam,org.apache.hadoop.hdfs.web.resources.DestinationParam,org.apache.hadoop.hdfs.web.resources.OwnerParam,org.apache.hadoop.hdfs.web.resources.GroupParam,org.apache.hadoop.hdfs.web.resources.PermissionParam,org.apache.hadoop.hdfs.web.resources.UnmaskedPermissionParam,org.apache.hadoop.hdfs.web.resources.OverwriteParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ReplicationParam,org.apache.hadoop.hdfs.web.resources.BlockSizeParam,org.apache.hadoop.hdfs.web.resources.ModificationTimeParam,org.apache.hadoop.hdfs.web.resources.AccessTimeParam,org.apache.hadoop.hdfs.web.resources.RenameOptionSetParam,org.apache.hadoop.hdfs.web.resources.CreateParentParam,org.apache.hadoop.hdfs.web.resources.TokenArgumentParam,org.apache.hadoop.hdfs.web.resources.AclPermissionParam,org.apache.hadoop.hdfs.web.resources.XAttrNameParam,org.apache.hadoop.hdfs.web.resources.XAttrValueParam,org.apache.hadoop.hdfs.web.resources.XAttrSetFlagParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.CreateFlagParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StoragePolicyParam,org.apache.hadoop.hdfs.web.resources.ECPolicyParam,org.apache.hadoop.hdfs.web.resources.NameSpaceQuotaParam,org.apache.hadoop.hdfs.web.resources.StorageSpaceQuotaParam,org.apache.hadoop.hdfs.web.resources.StorageTypeParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.postRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PostOpParam,org.apache.hadoop.hdfs.web.resources.ConcatSourcesParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.NewLengthParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.deleteRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.DeleteOpParam,org.apache.hadoop.hdfs.web.resources.RecursiveParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
2025-12-02 23:14:07,749 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.1	cmd=listStatus	src=/	dst=null	perm=null	proto=webhdfs
2025-12-02 23:14:08,068 INFO org.apache.hadoop.hdfs.StateChange - STATE* Safe mode ON, in safe mode extension. 
The reported blocks 72 has reached the threshold 0.9990 of total blocks 72. The minimum number of live datanodes is not required. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
2025-12-02 23:14:17,642 INFO BlockStateChange - BLOCK* processReport 0x45779e7798f2abc9 with lease ID 0xbdc3798b29bdcd82: discarded non-initial block report from DatanodeRegistration(172.18.0.2:9866, datanodeUuid=d02fd027-40dc-452a-aa59-17a9b2edb3fe, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-8de1d889-312c-47f1-9135-cecbc5761ae6;nsid=1122154000;c=1763416835540) because namenode still in startup phase
2025-12-02 23:14:20,798 INFO org.apache.hadoop.hdfs.StateChange - STATE* Safe mode is OFF
2025-12-02 23:14:20,799 INFO org.apache.hadoop.hdfs.StateChange - STATE* Leaving safe mode after 31 secs
2025-12-02 23:14:20,799 INFO org.apache.hadoop.hdfs.StateChange - STATE* Network topology has 1 racks and 1 datanodes
2025-12-02 23:14:20,799 INFO org.apache.hadoop.hdfs.StateChange - STATE* UnderReplicatedBlocks has 0 blocks
2025-12-02 23:15:42,071 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.4	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2025-12-02 23:15:42,094 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.4	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2025-12-02 23:15:42,109 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.4	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2025-12-02 23:15:42,111 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.4	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2025-12-02 23:15:42,114 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.4	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2025-12-02 23:15:42,115 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.4	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2025-12-02 23:15:42,119 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.4	cmd=slowDataNodesReport	src=null	dst=null	perm=null	proto=rpc
2025-12-02 23:16:22,896 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit - allowed=true	ugi=root (auth:SIMPLE)	ip=/172.18.0.1	cmd=listStatus	src=/	dst=null	perm=null	proto=webhdfs
